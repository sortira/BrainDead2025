{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas evaluate nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_iYC5XBOPaX",
        "outputId": "9bd6c931-e59d-41c0-cd15-32b2f3d72ce3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xacxZzZvOSPK",
        "outputId": "eb40b7e0-7180-44b4-e334-c190a0c30b22"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "veZvX59fONR8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yyhnKPZeKiTB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df_predictions = pd.read_csv(\"test_predictions.csv\")\n",
        "\n",
        "def extract_translation(text):\n",
        "    if isinstance(text, str):\n",
        "        match = re.search(r'\\n(.*)', text, re.DOTALL)\n",
        "        return match.group(1).strip() if match else text\n",
        "    return text\n",
        "\n",
        "df_predictions[\"predictions\"] = df_predictions[\"predictions\"].apply(extract_translation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# df_predictions = pd.read_csv(\"test_predictions.csv\")\n",
        "\n",
        "def extract_translation(text):\n",
        "    if isinstance(text, str):\n",
        "        match = re.search(r'@xcite(.*)', text, re.DOTALL)\n",
        "        return match.group(1).strip() if match else text\n",
        "    return text\n",
        "\n",
        "df_predictions[\"predictions\"] = df_predictions[\"predictions\"].apply(extract_translation)\n"
      ],
      "metadata": {
        "id": "oROXFcp3K4Zp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions[\"targets\"][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "jKJbQAZzK71T",
        "outputId": "85486fe1-0882-4461-b40c-57a5a71e76be"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The paper proposes a method called DEXPERTS for controlled text generation by combining a pretrained language model with expert and anti expert language models in a product of experts The approach is applied to language detoxification and sentiment controlled generation and outperforms existing controllable generation methods The method is effective with small expert and anti expert language models and highlights the promise of tuning language models for efficient decoding time steering towards safe and user friendly generations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions[\"predictions\"][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "AVtOOQhAK9LX",
        "outputId": "5101f4d9-1246-4836-f58e-a0c3ccbdb915"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "') . We propose DEXPERTS a decoding time method for controlled text generation that combines a pretrained language model with expert LMs and or anti expert LMs in a product of experts . Intuitively under the ensemble tokens only get high probabil ity if they are considered likely by the ex perts and unlikely by the anti experts . We ap ply DEXPERTS to language detoxification and sentiment controlled generation where we outperform existing controllable generation methods on both automatic and human evalua tions . Moreover because DEXPERTS operates only on the output of the pretrained LM it is effective with anti experts of smaller size in cluding when operating on GPT 3 . Our work highlights the promise of tuning small LMs on text with un desirable attributes for efficient decoding time steering .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VNSummarizer:\n",
        "    def __init__(self, documents, reference_summaries, max_summary_length=150):\n",
        "        self.documents = documents\n",
        "        self.reference_summaries = reference_summaries\n",
        "        self.max_summary_length = max_summary_length\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    def calculate_rouge(self, summary):\n",
        "        rouge1_scores = []\n",
        "        rouge2_scores = []\n",
        "        rougeL_scores = []\n",
        "\n",
        "        for ref in self.reference_summaries:\n",
        "            score = self.rouge_scorer.score(summary, ref)\n",
        "            rouge1_scores.append(score['rouge1'].fmeasure)\n",
        "            rouge2_scores.append(score['rouge2'].fmeasure)\n",
        "            rougeL_scores.append(score['rougeL'].fmeasure)\n",
        "\n",
        "        avg_rouge1 = np.mean(rouge1_scores)\n",
        "        avg_rouge2 = np.mean(rouge2_scores)\n",
        "        avg_rougeL = np.mean(rougeL_scores)\n",
        "\n",
        "        combined_score = (avg_rouge1 + avg_rouge2 + avg_rougeL) / 3\n",
        "\n",
        "        return combined_score\n",
        "\n",
        "    def shake(self, current_solution, k):\n",
        "        neighbor = current_solution.copy()\n",
        "        available_sentences = [s for s in range(len(self.documents)) if s not in neighbor]\n",
        "\n",
        "        if len(available_sentences) < k or len(neighbor) < k:\n",
        "            return neighbor\n",
        "\n",
        "        indices_to_replace = random.sample(range(len(neighbor)), k)\n",
        "        new_sentences = random.sample(available_sentences, k)\n",
        "\n",
        "        for i, idx in enumerate(indices_to_replace):\n",
        "            neighbor[idx] = new_sentences[i]\n",
        "\n",
        "        return neighbor\n",
        "\n",
        "    def local_search(self, solution):\n",
        "        improved = True\n",
        "        current_solution = solution.copy()\n",
        "        current_score = self.calculate_rouge(self.generate_summary(current_solution))\n",
        "\n",
        "        while improved:\n",
        "            improved = False\n",
        "            best_neighbor = current_solution\n",
        "            best_score = current_score\n",
        "\n",
        "            for i in range(len(current_solution)):\n",
        "                for j in range(len(self.documents)):\n",
        "                    if j not in current_solution:\n",
        "                        neighbor = current_solution.copy()\n",
        "                        neighbor[i] = j\n",
        "                        summary = self.generate_summary(neighbor)\n",
        "                        score = self.calculate_rouge(summary)\n",
        "\n",
        "                        if score > best_score:\n",
        "                            best_score = score\n",
        "                            best_neighbor = neighbor.copy()\n",
        "                            improved = True\n",
        "\n",
        "            if improved:\n",
        "                current_solution = best_neighbor\n",
        "                current_score = best_score\n",
        "\n",
        "        return current_solution, current_score\n",
        "\n",
        "    def generate_summary(self, indices):\n",
        "        selected_sentences = [self.documents[i] for i in indices]\n",
        "        return \" \".join(selected_sentences)\n",
        "\n",
        "    def summarize(self, max_iterations=100):\n",
        "        current_solution = random.sample(range(len(self.documents)),\n",
        "                                        min(5, len(self.documents)))\n",
        "        current_summary = self.generate_summary(current_solution)\n",
        "        current_score = self.calculate_rouge(current_summary)\n",
        "\n",
        "        k_max = min(5, len(self.documents) // 2)\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            k = 1\n",
        "            while k <= k_max:\n",
        "                neighbor = self.shake(current_solution, k)\n",
        "\n",
        "                local_solution, local_score = self.local_search(neighbor)\n",
        "\n",
        "                if local_score > current_score:\n",
        "                    current_solution = local_solution\n",
        "                    current_score = local_score\n",
        "                    k = 1\n",
        "                else:\n",
        "                    k += 1\n",
        "\n",
        "        final_summary = self.generate_summary(current_solution)\n",
        "\n",
        "        final_scores = {}\n",
        "        for ref in self.reference_summaries:\n",
        "            score = self.rouge_scorer.score(final_summary, ref)\n",
        "            for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "                if metric not in final_scores:\n",
        "                    final_scores[metric] = []\n",
        "                final_scores[metric].append(score[metric].fmeasure)\n",
        "\n",
        "        avg_scores = {metric: np.mean(scores) for metric, scores in final_scores.items()}\n",
        "\n",
        "        return final_summary, current_score, avg_scores\n"
      ],
      "metadata": {
        "id": "75ETbbmJK-S2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_corpus_bleu(references, candidates):\n",
        "    from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "    bleu1 = corpus_bleu(references, candidates, weights=(1, 0, 0, 0))\n",
        "    bleu2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0, 0))\n",
        "    bleu3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33, 0))\n",
        "    bleu4 = corpus_bleu(references, candidates, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "    return {\n",
        "        'bleu1': bleu1,\n",
        "        'bleu2': bleu2,\n",
        "        'bleu3': bleu3,\n",
        "        'bleu4': bleu4\n",
        "    }\n"
      ],
      "metadata": {
        "id": "wyAphxreMWNN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "documents = [str(doc).split('. ') if not isinstance(doc, float) else [str(doc)] for doc in df_predictions['predictions']]\n",
        "reference_summaries = df_predictions['targets']\n",
        "\n",
        "vns_summarizer = VNSummarizer(documents[0], [reference_summaries[0]])\n",
        "summary, combined_score, individual_scores = vns_summarizer.summarize()\n",
        "\n",
        "print(f\"Evaluation Summary:\")\n",
        "print(f\"ROUGE-1 F1 Score: {100*individual_scores['rouge1']:.2f}\")\n",
        "print(f\"ROUGE-2 F1 Score: {100*individual_scores['rouge2']:.2f}\")\n",
        "print(f\"ROUGE-L F1 Score: {100*individual_scores['rougeL']:.2f}\")\n",
        "bleu_scores = calculate_corpus_bleu(documents, reference_summaries)\n",
        "print(f\"BLEU Score: {100*max(bleu_scores['bleu1'],bleu_scores['bleu2'],bleu_scores['bleu3'],bleu_scores['bleu4']):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3T-jY-tLKDU",
        "outputId": "57ed34c6-4189-46ac-9284-689db67249ca"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Summary:\n",
            "ROUGE-1 F1 Score: 48.03\n",
            "ROUGE-2 F1 Score: 22.38\n",
            "ROUGE-L F1 Score: 34.41\n",
            "BLEU Score: 39.38\n"
          ]
        }
      ]
    }
  ]
}